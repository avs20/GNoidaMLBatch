{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FridayKaShow-Processor.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/avs20/GNoidaMLBatch/blob/master/FridayKaShow_Processor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-V0QrQTvOW-B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b16dfcd8-82c5-4eea-fb5f-faa20d40777b"
      },
      "source": [
        "import os       #importing os to set environment variable\n",
        "def install_java():\n",
        "  !apt-get install -y openjdk-8-jdk-headless -qq > /dev/null      #install openjdk\n",
        "  os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"     #set environment variable\n",
        "  !java -version       #check java version\n",
        "install_java()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "openjdk version \"11.0.3\" 2019-04-16\n",
            "OpenJDK Runtime Environment (build 11.0.3+7-Ubuntu-1ubuntu218.04.1)\n",
            "OpenJDK 64-Bit Server VM (build 11.0.3+7-Ubuntu-1ubuntu218.04.1, mixed mode, sharing)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgDHfbS0OyNa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "cc60b60c-009d-4b88-da21-efdbe187cb3c"
      },
      "source": [
        "!wget https://nlp.stanford.edu/software/stanford-corenlp-full-2018-10-05.zip https://nlp.stanford.edu/software/stanford-english-corenlp-2018-10-05-models.jar"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-24 05:08:11--  https://nlp.stanford.edu/software/stanford-corenlp-full-2018-10-05.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 393239982 (375M) [application/zip]\n",
            "Saving to: ‘stanford-corenlp-full-2018-10-05.zip’\n",
            "\n",
            "stanford-corenlp-fu 100%[===================>] 375.02M  9.60MB/s    in 28s     \n",
            "\n",
            "2019-05-24 05:08:40 (13.2 MB/s) - ‘stanford-corenlp-full-2018-10-05.zip’ saved [393239982/393239982]\n",
            "\n",
            "--2019-05-24 05:08:40--  https://nlp.stanford.edu/software/stanford-english-corenlp-2018-10-05-models.jar\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1038970602 (991M) [application/x-java-archive]\n",
            "Saving to: ‘stanford-english-corenlp-2018-10-05-models.jar’\n",
            "\n",
            "stanford-english-co 100%[===================>] 990.84M  4.80MB/s    in 63s     \n",
            "\n",
            "2019-05-24 05:09:43 (15.8 MB/s) - ‘stanford-english-corenlp-2018-10-05-models.jar’ saved [1038970602/1038970602]\n",
            "\n",
            "FINISHED --2019-05-24 05:09:43--\n",
            "Total wall clock time: 1m 31s\n",
            "Downloaded: 2 files, 1.3G in 1m 31s (15.0 MB/s)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYqPlpWvPsiN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1088
        },
        "outputId": "9004ec4e-1b59-41bd-83bc-8183d5cc11b4"
      },
      "source": [
        "!unzip stanford-corenlp-full-2018-10-05.zip\n",
        "!mv stanford-english-corenlp-2018-10-05-models.jar stanford-corenlp-full-2018-10-05"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  stanford-corenlp-full-2018-10-05.zip\n",
            "   creating: stanford-corenlp-full-2018-10-05/\n",
            "  inflating: stanford-corenlp-full-2018-10-05/jaxb-core-2.3.0.1-sources.jar  \n",
            "  inflating: stanford-corenlp-full-2018-10-05/xom-1.2.10-src.jar  \n",
            "  inflating: stanford-corenlp-full-2018-10-05/CoreNLP-to-HTML.xsl  \n",
            "  inflating: stanford-corenlp-full-2018-10-05/README.txt  \n",
            "  inflating: stanford-corenlp-full-2018-10-05/jollyday-0.4.9-sources.jar  \n",
            "  inflating: stanford-corenlp-full-2018-10-05/LIBRARY-LICENSES  \n",
            "   creating: stanford-corenlp-full-2018-10-05/sutime/\n",
            "  inflating: stanford-corenlp-full-2018-10-05/sutime/british.sutime.txt  \n",
            "  inflating: stanford-corenlp-full-2018-10-05/sutime/defs.sutime.txt  \n",
            "  inflating: stanford-corenlp-full-2018-10-05/sutime/spanish.sutime.txt  \n",
            "  inflating: stanford-corenlp-full-2018-10-05/sutime/english.sutime.txt  \n",
            "  inflating: stanford-corenlp-full-2018-10-05/sutime/english.holidays.sutime.txt  \n",
            " extracting: stanford-corenlp-full-2018-10-05/ejml-0.23-src.zip  \n",
            "  inflating: stanford-corenlp-full-2018-10-05/input.txt.xml  \n",
            "  inflating: stanford-corenlp-full-2018-10-05/build.xml  \n",
            "  inflating: stanford-corenlp-full-2018-10-05/pom.xml  \n",
            "  inflating: stanford-corenlp-full-2018-10-05/stanford-corenlp-3.9.2-javadoc.jar  \n",
            "   creating: stanford-corenlp-full-2018-10-05/tokensregex/\n",
            "  inflating: stanford-corenlp-full-2018-10-05/tokensregex/color.input.txt  \n",
            "  inflating: stanford-corenlp-full-2018-10-05/tokensregex/retokenize.txt  \n",
            "  inflating: stanford-corenlp-full-2018-10-05/tokensregex/color.properties  \n",
            "  inflating: stanford-corenlp-full-2018-10-05/tokensregex/color.rules.txt  \n",
            "  inflating: stanford-corenlp-full-2018-10-05/javax.json-api-1.0-sources.jar  \n",
            "  inflating: stanford-corenlp-full-2018-10-05/jaxb-api-2.4.0-b180830.0359-sources.jar  \n",
            "  inflating: stanford-corenlp-full-2018-10-05/stanford-corenlp-3.9.2-models.jar  \n",
            "  inflating: stanford-corenlp-full-2018-10-05/protobuf.jar  \n",
            "  inflating: stanford-corenlp-full-2018-10-05/javax.activation-api-1.2.0.jar  \n",
            "  inflating: stanford-corenlp-full-2018-10-05/StanfordDependenciesManual.pdf  \n",
            "   creating: stanford-corenlp-full-2018-10-05/patterns/\n",
            "  inflating: stanford-corenlp-full-2018-10-05/patterns/example.properties  \n",
            " extracting: stanford-corenlp-full-2018-10-05/patterns/otherpeople.txt  \n",
            " extracting: stanford-corenlp-full-2018-10-05/patterns/goldplaces.txt  \n",
            "  inflating: stanford-corenlp-full-2018-10-05/patterns/stopwords.txt  \n",
            "  inflating: stanford-corenlp-full-2018-10-05/patterns/presidents.txt  \n",
            "  inflating: stanford-corenlp-full-2018-10-05/patterns/names.txt  \n",
            " extracting: stanford-corenlp-full-2018-10-05/patterns/places.txt  \n",
            "  inflating: stanford-corenlp-full-2018-10-05/patterns/goldnames.txt  \n",
            "  inflating: stanford-corenlp-full-2018-10-05/slf4j-simple.jar  \n",
            "  inflating: stanford-corenlp-full-2018-10-05/stanford-corenlp-3.9.2-sources.jar  \n",
            "  inflating: stanford-corenlp-full-2018-10-05/input.txt  \n",
            "  inflating: stanford-corenlp-full-2018-10-05/joda-time.jar  \n",
            "  inflating: stanford-corenlp-full-2018-10-05/xom.jar  \n",
            "  inflating: stanford-corenlp-full-2018-10-05/jaxb-impl-2.4.0-b180830.0438-sources.jar  \n",
            "  inflating: stanford-corenlp-full-2018-10-05/StanfordCoreNlpDemo.java  \n",
            "  inflating: stanford-corenlp-full-2018-10-05/jaxb-core-2.3.0.1.jar  \n",
            "  inflating: stanford-corenlp-full-2018-10-05/RESOURCE-LICENSES  \n",
            "  inflating: stanford-corenlp-full-2018-10-05/javax.activation-api-1.2.0-sources.jar  \n",
            "  inflating: stanford-corenlp-full-2018-10-05/slf4j-api.jar  \n",
            "  inflating: stanford-corenlp-full-2018-10-05/pom-java-11.xml  \n",
            "  inflating: stanford-corenlp-full-2018-10-05/ejml-0.23.jar  \n",
            "  inflating: stanford-corenlp-full-2018-10-05/javax.json.jar  \n",
            "  inflating: stanford-corenlp-full-2018-10-05/Makefile  \n",
            "  inflating: stanford-corenlp-full-2018-10-05/corenlp.sh  \n",
            "  inflating: stanford-corenlp-full-2018-10-05/joda-time-2.9-sources.jar  \n",
            "  inflating: stanford-corenlp-full-2018-10-05/jaxb-api-2.4.0-b180830.0359.jar  \n",
            "  inflating: stanford-corenlp-full-2018-10-05/jollyday.jar  \n",
            "  inflating: stanford-corenlp-full-2018-10-05/ShiftReduceDemo.java  \n",
            "  inflating: stanford-corenlp-full-2018-10-05/jaxb-impl-2.4.0-b180830.0438.jar  \n",
            "  inflating: stanford-corenlp-full-2018-10-05/stanford-corenlp-3.9.2.jar  \n",
            "  inflating: stanford-corenlp-full-2018-10-05/SemgrexDemo.java  \n",
            "  inflating: stanford-corenlp-full-2018-10-05/LICENSE.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1UW2JuxP86l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "95374ceb-0ed1-4912-b2de-d55483d30f18"
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\t\t\t  stanford-corenlp-full-2018-10-05.zip\n",
            "stanford-corenlp-full-2018-10-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MmCAXcXOlKo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "361b8f37-3221-4ad0-c4ec-e76883b8c5c2"
      },
      "source": [
        "!pip install StanfordCoreNLP\n",
        "from stanfordcorenlp import StanfordCoreNLP\n",
        "nlp = StanfordCoreNLP('stanford-corenlp-full-2018-10-05', lang='en', memory='4g')\n",
        "\n",
        "sentence = 'Guangdong University of Foreign Studies is located in Guangzhou.'\n",
        "print('Tokenize:', nlp.word_tokenize(sentence))\n",
        "print('Part of Speech:', nlp.pos_tag(sentence))\n",
        "print('Named Entities:', nlp.ner(sentence))\n",
        "print('Constituency Parsing:', nlp.parse(sentence))\n",
        "print('Dependency Parsing:', nlp.dependency_parse(sentence))\n",
        "\n",
        "nlp.close()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: StanfordCoreNLP in /usr/local/lib/python3.6/dist-packages (3.9.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from StanfordCoreNLP) (2.21.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from StanfordCoreNLP) (5.4.8)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->StanfordCoreNLP) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->StanfordCoreNLP) (2019.3.9)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->StanfordCoreNLP) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->StanfordCoreNLP) (1.24.3)\n",
            "Tokenize: ['Guangdong', 'University', 'of', 'Foreign', 'Studies', 'is', 'located', 'in', 'Guangzhou', '.']\n",
            "Part of Speech: [('Guangdong', 'NNP'), ('University', 'NNP'), ('of', 'IN'), ('Foreign', 'NNP'), ('Studies', 'NNPS'), ('is', 'VBZ'), ('located', 'JJ'), ('in', 'IN'), ('Guangzhou', 'NNP'), ('.', '.')]\n",
            "Named Entities: [('Guangdong', 'ORGANIZATION'), ('University', 'ORGANIZATION'), ('of', 'ORGANIZATION'), ('Foreign', 'ORGANIZATION'), ('Studies', 'ORGANIZATION'), ('is', 'O'), ('located', 'O'), ('in', 'O'), ('Guangzhou', 'CITY'), ('.', 'O')]\n",
            "Constituency Parsing: (ROOT\n",
            "  (S\n",
            "    (NP\n",
            "      (NP (NNP Guangdong) (NNP University))\n",
            "      (PP (IN of)\n",
            "        (NP (NNP Foreign) (NNPS Studies))))\n",
            "    (VP (VBZ is)\n",
            "      (VP (JJ located)\n",
            "        (PP (IN in)\n",
            "          (NP (NNP Guangzhou)))))\n",
            "    (. .)))\n",
            "Dependency Parsing: [('ROOT', 0, 7), ('compound', 2, 1), ('nsubjpass', 7, 2), ('case', 5, 3), ('compound', 5, 4), ('nmod', 2, 5), ('auxpass', 7, 6), ('case', 9, 8), ('nmod', 7, 9), ('punct', 7, 10)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKq7L3lHVWP-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0ac31cc6-91eb-40e6-fd7d-4f2a9fca177d"
      },
      "source": [
        "print(nlp)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<stanfordcorenlp.corenlp.StanfordCoreNLP object at 0x7f2394954828>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5LqmckxVX0y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        },
        "outputId": "97267b08-50fe-4255-f5aa-3f3b8a456021"
      },
      "source": [
        "help(nlp)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on StanfordCoreNLP in module stanfordcorenlp.corenlp object:\n",
            "\n",
            "class StanfordCoreNLP(builtins.object)\n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __enter__(self)\n",
            " |  \n",
            " |  __exit__(self, exc_type, exc_val, exc_tb)\n",
            " |  \n",
            " |  __init__(self, path_or_host, port=None, memory='4g', lang='en', timeout=1500, quiet=True, logging_level=30)\n",
            " |      Initialize self.  See help(type(self)) for accurate signature.\n",
            " |  \n",
            " |  annotate(self, text, properties=None)\n",
            " |  \n",
            " |  close(self)\n",
            " |  \n",
            " |  coref(self, text)\n",
            " |  \n",
            " |  dependency_parse(self, sentence)\n",
            " |  \n",
            " |  ner(self, sentence)\n",
            " |  \n",
            " |  parse(self, sentence)\n",
            " |  \n",
            " |  pos_tag(self, sentence)\n",
            " |  \n",
            " |  semgrex(self, sentence, pattern)\n",
            " |  \n",
            " |  switch_language(self, language='en')\n",
            " |  \n",
            " |  tokensregex(self, sentence, pattern)\n",
            " |  \n",
            " |  tregex(self, sentence, pattern)\n",
            " |  \n",
            " |  word_tokenize(self, sentence, span=False)\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors defined here:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64zbE94zVZ8R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "b50bd94c-d5c4-4730-9e40-d4a3eccc7a05"
      },
      "source": [
        "help(nlp.annotate)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on method annotate in module stanfordcorenlp.corenlp:\n",
            "\n",
            "annotate(text, properties=None) method of stanfordcorenlp.corenlp.StanfordCoreNLP instance\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MhCPKNRVgTh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "1e1fc5d6-f317-4733-fb63-b476fa10a46b"
      },
      "source": [
        "nlp = StanfordCoreNLP('stanford-corenlp-full-2018-10-05', lang='en', memory='4g')\n",
        "\n",
        "sentence = \"This movie was actually neither that funny, nor super witty. The movie was meh. I liked watching that movie. If I had a choice, I would not watch that movie again.\"\n",
        "\n",
        "properties={ 'annotators': 'sentiment',\n",
        "                       'outputFormat': 'json',\n",
        "                       'timeout': 1000\n",
        "                   }\n",
        "result = nlp.annotate(sentence, properties=properties)\n",
        "\n",
        "for s in result[\"sentences\"]:\n",
        "    print(\"{}: '{}': {} (Sentiment Value) {} (Sentiment)\".format(\n",
        "        s[\"index\"],\n",
        "        \" \".join([t[\"word\"] for t in s[\"tokens\"]]),\n",
        "        s[\"sentimentValue\"], s[\"sentiment\"]))\n",
        "\n",
        "nlp.close()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-9fb13880ba36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproperties\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproperties\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sentences\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     print(\"{}: '{}': {} (Sentiment Value) {} (Sentiment)\".format(\n\u001b[1;32m     13\u001b[0m         \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"index\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNiyr-dGVylx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "7ec67789-621e-473c-e933-e83e7bd40eb5"
      },
      "source": [
        "import json\n",
        "result = json.loads(result)\n",
        "\n",
        "for s in result[\"sentences\"]:\n",
        "    print(\"{}: '{}': {} (Sentiment Value) {} (Sentiment)\".format(\n",
        "        s[\"index\"],\n",
        "        \" \".join([t[\"word\"] for t in s[\"tokens\"]]),\n",
        "        s[\"sentimentValue\"], s[\"sentiment\"]))\n",
        "\n",
        "nlp.close()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0: 'This movie was actually neither that funny , nor super witty .': 1 (Sentiment Value) Negative (Sentiment)\n",
            "1: 'The movie was meh .': 2 (Sentiment Value) Neutral (Sentiment)\n",
            "2: 'I liked watching that movie .': 3 (Sentiment Value) Positive (Sentiment)\n",
            "3: 'If I had a choice , I would not watch that movie again .': 1 (Sentiment Value) Negative (Sentiment)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fUsEWFQc5zp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "eefc15ee-8f78-4ada-a3fd-70bd3a8fadef"
      },
      "source": [
        "result['sentences'][0]['sentimentDistribution']"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.18668278907607,\n",
              " 0.52243946222855,\n",
              " 0.1286760912247,\n",
              " 0.1111918907674,\n",
              " 0.05100976670328]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKX-QeACdM5I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}